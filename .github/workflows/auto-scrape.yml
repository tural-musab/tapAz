name: Auto Tap.az Scraper

on:
  schedule:
    - cron: '0 22 * * *' # UTC 22:00 ≈ Bakı 02:00
  workflow_dispatch:

env:
  ADMIN_ENDPOINT: ${{ vars.ADMIN_ENDPOINT }}
  ADMIN_TOKEN: ${{ secrets.ADMIN_DASHBOARD_TOKEN }}

jobs:
  auto-scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Fetch auto plan
        id: plan
        env:
          ADMIN_ENDPOINT: ${{ env.ADMIN_ENDPOINT }}
          ADMIN_TOKEN: ${{ env.ADMIN_TOKEN }}
        run: |
          if [ -z "${ADMIN_ENDPOINT}" ]; then
            echo "ADMIN_ENDPOINT GitHub var dəyəri təyin edilməyib." >&2
            exit 1
          fi

          if [ -z "${ADMIN_TOKEN}" ]; then
            echo "ADMIN_DASHBOARD_TOKEN secret-i təyin edilməyib." >&2
            exit 1
          fi

          API_URL="${ADMIN_ENDPOINT%/}/api/admin/plan"
          echo "Plan ${API_URL} endpoint-indən oxunur..."
          RESPONSE=$(
            curl -sfL \
              -H "x-admin-token: ${ADMIN_TOKEN}" \
              "${API_URL}"
          )

          echo "${RESPONSE}" > plan.json
          CATEGORY_URLS_JSON=$(jq -r '.categoryQueue | map(.url) | @json' plan.json)
          CATEGORY_URLS_RAW=$(jq -r '.categoryQueue | map(.url) | join(",")' plan.json)

          if [ -z "${CATEGORY_URLS_JSON}" ] || [ "${CATEGORY_URLS_JSON}" = "null" ]; then
            echo "Plan cavabında categoryQueue tapılmadı." >&2
            exit 1
          fi

          if [ -z "${CATEGORY_URLS_RAW}" ] || [ "${CATEGORY_URLS_RAW}" = "" ]; then
            echo "Plan kateqoriya qaytarmadı, job atlanır."
            echo "shouldSkip=true" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          echo "shouldSkip=false" >> "$GITHUB_OUTPUT"
          echo "categoryUrls=${CATEGORY_URLS_JSON}" >> "$GITHUB_OUTPUT"
          echo "categoryUrlsRaw=${CATEGORY_URLS_RAW}" >> "$GITHUB_OUTPUT"

      - name: Run Playwright collector
        if: steps.plan.outputs.shouldSkip != 'true'
        env:
          SCRAPE_CATEGORY_URLS: ${{ steps.plan.outputs.categoryUrlsRaw }}
          SCRAPE_MAX_PAGES: ${{ vars.SCRAPE_MAX_PAGES || '2' }}
          SCRAPE_MAX_LISTINGS: ${{ vars.SCRAPE_MAX_LISTINGS || '120' }}
          SCRAPE_DELAY_MS: ${{ vars.SCRAPE_DELAY_MS || '1500' }}
          SCRAPE_DETAIL_DELAY_MS: ${{ vars.SCRAPE_DETAIL_DELAY_MS || '2200' }}
          SCRAPE_HEADLESS: 'true'
          SCRAPE_CF_CLEARANCE: ${{ secrets.SCRAPE_CF_CLEARANCE }}
          SCRAPE_CF_DOMAIN: ${{ vars.SCRAPE_CF_DOMAIN || '.tap.az' }}
        run: |
          npx playwright install --with-deps chromium
          npx tsx scripts/tapazCollector.playwright.ts

      - name: Upload snapshot to Supabase
        if: steps.plan.outputs.shouldSkip != 'true'
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          npx tsx scripts/uploadSnapshotToSupabase.ts gha-${{ github.run_id }}

      - name: Upload latest snapshot artifact
        if: steps.plan.outputs.shouldSkip != 'true' && always() && hashFiles('data/snapshots/*.json') != ''
        uses: actions/upload-artifact@v4
        with:
          name: tapaz-snapshot
          path: data/snapshots/*.json
          retention-days: 7
